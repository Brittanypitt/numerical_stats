{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 10\n",
    "====\n",
    "#### CHE 116: Numerical Methods and Statistics\n",
    "\n",
    "5/5/2018\n",
    "\n",
    "----\n",
    "\n",
    "Homework Requirements:\n",
    "\n",
    "1. Write all equations in $\\LaTeX$\n",
    "2. Simplify all expressions\n",
    "2. Put comments in your Python code\n",
    "3. Explain or show your work\n",
    "4. Follow the academic honesty guidelines in the syllabus\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Conceptual Questions\n",
    "====\n",
    "\n",
    "1. In the following picture, which color area corresponds to the p-value? \n",
    "    ![image-not-visible](./pvalue.png)\n",
    "2. If a significance level goes up, is it easier or harder to reject a null hypothesis?\n",
    "3. If you only have one data point, which hypothesis test or tests can be used?\n",
    "4. Is it meaningful to perform a Wilcoxon Signed Rank Test if the two paired data are in different unit systems?\n",
    "5. We haven't learned about a \"binomial hypothesis test\", but what would the null hypothesis of such a test be and provide a situation where you would use it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "Blue\n",
    "### 1.2\n",
    "easier\n",
    "### 1.3\n",
    "zM test\n",
    "### 1.4\n",
    "yes\n",
    "### 1.5\n",
    "a count out of N came from a population binomial distribution. You count how many questions out of 6 you get correct on a homework when you normally have a probability of 0.3 of getting a question correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Hypothesis Tests\n",
    "====\n",
    "\n",
    "For the following questions, state the following in Markdown and show your numerical work in Python:\n",
    "\n",
    "* The null hypothesis\n",
    "* The choice of test\n",
    "* The $p$-value and if you are considering both tails (extreme values above and below) or only one side\n",
    "* If the null hypothesis is rejected\n",
    "\n",
    "*Each hypothesis test occurs once in the following, so make sure you do not repeat any of them!*\n",
    "\n",
    "1. On average, 3 people fall asleep in class. Today 11 fall asleep in class. Is this significant?\n",
    "2. Your average running pace over the last few years has been an 8:00 minute mile. You've tried changing running shoes and recorded the following paces on your most recent runs: 7:56, 7:45, 7:34, 8:05, 7:35. Is your running pace significantly different?\n",
    "3. You are comparing two batches of a compound prepared by different technicians. The following purities have been recorded for technician A: 0.87, 0.86, 0.88, 0.93, 0.85, 0.67 and the following by technician B: 0.86, 0.96, 0.90, 0.76, 0.87, 0.83, 0.84, 0.80. Are they achiving similar purity?\n",
    "4. You are assessing the efficacy of a drug that helps people lose weight. 13 people who enrolled had the following weights at admission and after 8 weeks of the drug:\n",
    "\n",
    "|Person|Weight at Start|Weight at 8 Weeks|\n",
    "|:----|:----:|----:|\n",
    "|  1 | 150 | 163 |\n",
    "|  2 | 212 | 194 |\n",
    "|  3 | 320 | 280 |\n",
    "|  4 | 250 | 265 |\n",
    "|  5 | 215 | 132 |\n",
    "|  6 | 186 | 172 |\n",
    "|  7 | 195 | 185 |\n",
    "|  8 | 203 | 187 |\n",
    "|  9 | 145 | 135 |\n",
    "| 10 | 168 | 140 |\n",
    "| 11 | 172 | 178 |\n",
    "| 12 | 240 | 211 |\n",
    "| 13 | 272 | 268 |\n",
    "\n",
    "is there a significant effect from the drug?\n",
    "\n",
    "5\\. A chemical refinery has input crude with a concentration of sulfor of 0.7% on average with a variance of 0.015%. A sample from the crude reveals a concentration of 1.2%. Is this significant enough that you should investigate?\n",
    "\n",
    "6\\. You are assessing if a correlation exists between literacy rate and birthrate. You've found the following data from countries:\n",
    "\n",
    "| Country | Literacy Rate | Birthrate per 1000 |\n",
    "| ----    | :-----------: | --------: |\n",
    "| Afghanistan |  \t38.2% | 37.90 |\n",
    "| Belize      |  82.7% | 24.00 |\n",
    "|  Laos        | 79.9%| 23.60|\n",
    "| Lebanon |\t93.9% | 14.30|\n",
    "| India |\t72.1% | 19.00 |\n",
    "| Russia | \t99.7% | 11.00|\n",
    "|  Argentina | \t98.1% | 16.70|\n",
    "| South Africa \t| 94.3%| 20.20|\n",
    "|Venezuela | \t95.4%| 18.80 |\n",
    "|  Cameroon | \t75% | 35.40|\n",
    "| Chad \t| 40.2%|  35.60| \n",
    "\n",
    "Is there a relationship between these two?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "* This is a sample from the population Poisson\n",
    "* Poisson test\n",
    "* 0.0003\n",
    "* reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002923369506473428\n"
     ]
    }
   ],
   "source": [
    "#2.1\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "print(1 - ss.poisson.cdf(11 - 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "* These times come from our population normal distribution\n",
    "* t-test\n",
    "* 0.0965\n",
    "* do not reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16366366222047 0.09649223504829538 7.783333333333333\n"
     ]
    }
   ],
   "source": [
    "#2.2\n",
    "#must convert to sceonds!\n",
    "times = [ 7 * 60 + 56, 7 * 60 + 45, 7 * 60 + 34, 8 * 60 + 5, 7 * 60 + 35]\n",
    "T = (8 * 60 - np.mean(times)) / (np.std(times, ddof=1) / np.sqrt(len(times)))\n",
    "# we look at both sides\n",
    "p = 2 * ss.t.cdf(-T, len(times) - 1)\n",
    "#print stat and p value and new mean\n",
    "print(T, p, np.mean(times) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "* These two numbers are from the same distribution\n",
    "* Wilcoxon sum of ranks\n",
    "* 0.70\n",
    "* do not reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985353583033387\n"
     ]
    }
   ],
   "source": [
    "A = [0.87, 0.86, 0.88, 0.93, 0.85, 0.67]\n",
    "B = [0.86, 0.96, 0.90, 0.76, 0.87, 0.83, 0.84, 0.80]\n",
    "\n",
    "print(ss.ranksums(A, B).pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4\n",
    "* The two sets of numbers are from the same distribution\n",
    "* Wilcoxon Signed Rank Test\n",
    "* 0.028\n",
    "* Reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=14.0, pvalue=0.027660332975047608)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.4\n",
    "# use python list to array syntax\n",
    "data = np.array([\n",
    "[ 1, 150, 163],\n",
    "[ 2, 212, 194],\n",
    "[ 3, 320, 280],\n",
    "[ 4, 250, 265],\n",
    "[ 5, 215, 132],\n",
    "[ 6, 186, 172],\n",
    "[ 7, 195, 185],\n",
    "[ 8, 203, 187],\n",
    "[ 9, 145, 135],\n",
    "[10, 168, 140],\n",
    "[11, 172, 178],\n",
    "[12, 240, 211],\n",
    "[13, 272, 268]\n",
    "])\n",
    "ss.wilcoxon(data[:,1], data[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5\n",
    "* The sample is from the normal population\n",
    "* zM test\n",
    "* ~0\n",
    "* reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.455709060402491e-05\n"
     ]
    }
   ],
   "source": [
    "# 2.5\n",
    "#quick syntax without making z score\n",
    "# CDF here is from -\\infty up to high value\n",
    "# 1 - includes top interval\n",
    "# 2 * to get bottom interval\n",
    "print(2 * (1 - ss.norm.cdf(1.2, loc=0.7, scale=np.sqrt(0.015))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6\n",
    "* There is no correlation between literacy rate and birthrate\n",
    "* Spearman Correlation Test\n",
    "* 0.001\n",
    "* reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.8363636363636365, pvalue=0.0013331850799508562)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.6\n",
    "data = np.array([\n",
    "    [38.2,37.90],\n",
    "[82.7,24.00],\n",
    "[79.9,23.60],\n",
    "[93.9,14.30],\n",
    "[72.1,19.00],\n",
    "[99.7,11.00],\n",
    "[98.1,16.70],\n",
    "[94.3,20.20],\n",
    "[95.4,18.80],\n",
    "[75,35.40],\n",
    "[40.2,35.60]\n",
    "])\n",
    "\n",
    "ss.spearmanr(data[:,0], data[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
